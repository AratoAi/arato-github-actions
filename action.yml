name: 'Arato Build Action'
description: 'Build and monitor Arato AI experiments with automatic progress tracking'
author: 'AratoAi'

branding:
  icon: 'activity'
  color: 'blue'

inputs:
  experiments:
    description: 'Experiment(s) to build. Use either a single experiment ID like "flow_id/experiment_id" or a JSON array like ["flow_id/exp1", "flow_id/exp2"]'
    required: true
  api_keys:
    description: 'API keys for AI model providers as a JSON object (e.g., {"openai_api_key": "sk-...", "anthropic_api_key": "ant-..."})'
    required: true
  api_base_url:
    description: 'Arato API base URL (defaults to production)'
    required: false
    default: 'https://api.arato.ai'
  arato_api_key:
    description: 'Your Arato API key (starts with "ar-")'
    required: true
  threshold:
    description: 'Optional threshold configuration as JSON object with numeric values for performance metrics (e.g., {"eval_pass_rate": 0.8, "cost": 0.01, "latency": 3000, "tokens": 100, "semantic_similarity": 0.7})'
    required: false

outputs:
  success:
    description: 'Whether all builds completed successfully (true/false)'
    value: ${{ steps.summary.outputs.success }}
  completed_count:
    description: 'Number of experiments that completed successfully'
    value: ${{ steps.summary.outputs.completed_count }}
  failed_count:
    description: 'Number of experiments that failed'
    value: ${{ steps.summary.outputs.failed_count }}
  results_summary:
    description: 'Summary of build results as JSON'
    value: ${{ steps.summary.outputs.results_summary }}
  threshold_failures:
    description: 'List of threshold validation failures'
    value: ${{ steps.summary.outputs.threshold_failures }}

runs:
  using: 'composite'
  steps:
    - name: Validate inputs
      shell: bash
      run: |
        # Validate experiments format
        if [[ '${{ inputs.experiments }}' =~ ^\[.*\]$ ]]; then
          echo "‚úì Multiple experiments provided"
          echo '${{ inputs.experiments }}' | jq empty || (echo "‚ùå Invalid JSON array format" && exit 1)
        else
          echo "‚úì Single experiment provided: ${{ inputs.experiments }}"
        fi
        
        # Validate API keys format
        echo '${{ inputs.api_keys }}' | jq empty || (echo "‚ùå Invalid JSON format for API keys" && exit 1)
        echo "‚úì API keys format validated"
        
        # Validate threshold format if provided
        if [[ -n '${{ inputs.threshold }}' ]]; then
          echo '${{ inputs.threshold }}' | jq empty || (echo "‚ùå Invalid JSON format for threshold" && exit 1)
          echo "‚úì Threshold format validated"
        else
          echo "‚úì No threshold provided"
        fi

    - name: Trigger Arato build
      shell: bash
      id: build
      run: |
        # Prepare experiment data
        if [[ '${{ inputs.experiments }}' =~ ^\[.*\]$ ]]; then
          experiments='${{ inputs.experiments }}'
        else
          experiments='"${{ inputs.experiments }}"'
        fi
        
        # Create request payload
        payload=$(jq -n \
          --argjson experiment "$experiments" \
          --argjson api_keys '${{ inputs.api_keys }}' \
          '{experiment: $experiment, api_keys: $api_keys}')
        
        echo "üöÄ Starting Arato build..."
        
        
        # Make API call
        response=$(curl -s -w "\n%{http_code}" \
          -X POST \
          -H "Content-Type: application/json" \
          -H "Authorization: Bearer ${{ inputs.arato_api_key }}" \
          -d "$payload" \
          "${{ inputs.api_base_url }}/api/build")
        
        # Parse response
        http_code=$(echo "$response" | tail -n1)
        response_body=$(echo "$response" | head -n -1)
        
        if [[ "$http_code" =~ ^2[0-9][0-9]$ ]]; then
          # Validate response is JSON before declaring success
          if ! echo "$response_body" | jq empty 2>/dev/null; then
            echo "‚ùå Build failed: API returned non-JSON response (likely authentication error)"
            echo "Response body: $response_body"
            echo "build_success=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          echo "‚úÖ Build started successfully"
          echo "build_success=true" >> $GITHUB_OUTPUT
          
          # Extract experiment IDs for monitoring
          echo "Response body for debugging: $response_body"
          if echo "$response_body" | jq -e '.builds' >/dev/null 2>&1; then
            # Handle nested builds structure with steps
            if echo "$response_body" | jq -e '.builds[0].builds[0].steps' >/dev/null 2>&1; then
              # Extract all step IDs from the nested structure recursively
              experiment_ids=$(echo "$response_body" | jq -r '
                def extract_all_steps:
                  if type == "object" then
                    (if has("step") then [.step] else [] end) +
                    (if has("steps") then [.steps[] | extract_all_steps] | flatten else [] end)
                  elif type == "array" then
                    [.[] | extract_all_steps] | flatten
                  else
                    []
                  end;
                [.builds[].builds[].steps[] | extract_all_steps] | flatten | @json
              ')
            # Handle simple builds structure: builds[].run_id
            elif echo "$response_body" | jq -e '.builds[0].run_id' >/dev/null 2>&1; then
              experiment_ids=$(echo "$response_body" | jq -r '[.builds[].run_id] | @json')
            else
              experiment_ids='[]'
            fi
          elif echo "$response_body" | jq -e '.run_id' >/dev/null 2>&1; then
            experiment_ids=$(echo "$response_body" | jq -r '[.run_id] | @json')
          else
            # Fallback: try to extract any experiment-like ID from the response
            if echo "$response_body" | jq -e '.experiment_id' >/dev/null 2>&1; then
              experiment_ids=$(echo "$response_body" | jq -r '[.experiment_id] | @json')
            else
              experiment_ids='[]'
            fi
          fi
          
          echo "experiment_ids=$experiment_ids" >> $GITHUB_OUTPUT
          echo "Found experiments to monitor: $experiment_ids"
        else
          echo "‚ùå Build failed with HTTP $http_code"
          echo "$response_body"
          echo "build_success=false" >> $GITHUB_OUTPUT
          exit 1
        fi

    - name: Monitor build progress
      shell: bash
      id: monitor
      if: steps.build.outputs.build_success == 'true'
      run: |
        echo "üîç Monitoring build progress..."
        
        experiment_ids='${{ steps.build.outputs.experiment_ids }}'
        
        # Debug the experiment_ids
        echo "Experiment IDs received: $experiment_ids"
        
        if [[ "$experiment_ids" == "[]" || -z "$experiment_ids" ]]; then
          # Fallback: use the original input experiment if no IDs were extracted
          echo "No experiment IDs extracted, using input experiment"
          if [[ '${{ inputs.experiments }}' =~ ^\[.*\]$ ]]; then
            experiments=($(echo '${{ inputs.experiments }}' | jq -r '.[]'))
          else
            experiments=('${{ inputs.experiments }}')
          fi
        else
          experiments=($(echo "$experiment_ids" | jq -r '.[]'))
        fi
        
        if [[ ${#experiments[@]} -eq 0 ]]; then
          echo "‚ö†Ô∏è No experiments to monitor"
          echo "completed=0" >> $GITHUB_OUTPUT
          echo "failed=0" >> $GITHUB_OUTPUT
          echo "results={}" >> $GITHUB_OUTPUT
          exit 0
        fi
        
        echo "Monitoring ${#experiments[@]} experiment(s)..."
        
        # Debug: Print the experiments we're monitoring
        echo "üîç Experiments to monitor:"
        for exp in "${experiments[@]}"; do
          echo "  - $exp"
        done
        
        # Track progress
        declare -A status
        declare -A results
        completed=0
        failed=0
        max_wait_minutes=10
        polling_interval=10
        max_iterations=$((max_wait_minutes * 60 / polling_interval))
        
        for exp in "${experiments[@]}"; do
          status["$exp"]="running"
        done
        
        # Monitor loop
        for ((i=1; i<=max_iterations; i++)); do
          echo "üîÑ Check $i/$max_iterations"
          
          for exp in "${experiments[@]}"; do
            if [[ "${status[$exp]}" == "running" ]]; then
              echo "  üì° Checking status of $exp..."
              
              response=$(curl -s -w "\n%{http_code}" \
                -H "Authorization: Bearer ${{ inputs.arato_api_key }}" \
                "${{ inputs.api_base_url }}/api/$exp") || {
                echo "  ‚ö†Ô∏è Curl failed for $exp, will retry"
                continue
              }
              
              http_code=$(echo "$response" | tail -n1)
              response_body=$(echo "$response" | head -n -1)
              
              # Debug: print the raw response
              echo "  üìã Debug - API response for $exp:"
              echo "  üìã HTTP Code: $http_code"
              echo "  üìã Response Body: $response_body"
              
              if [[ "$http_code" == "200" ]] && [[ -n "$response_body" ]] && echo "$response_body" | jq empty >/dev/null 2>&1; then
                # Check if response is not empty JSON (empty {} means still running)
                if [[ "$response_body" == "{}" ]] || [[ "$(echo "$response_body" | jq 'length')" == "0" ]]; then
                  echo "  ‚è≥ $exp still running (empty response)"
                else
                  # Valid JSON response with content means completed
                  echo "  ‚úÖ $exp completed"
                  status["$exp"]="completed"
                  results["$exp"]="$response_body"
                  completed=$((completed + 1))
                  echo "  üìä Total completed: $completed"
                fi
              elif [[ "$http_code" =~ ^4[0-9][0-9]$ ]]; then
                echo "  ‚ùå $exp failed (HTTP $http_code)"
                status["$exp"]="failed"
                failed=$((failed + 1))
                echo "  üìä Total failed: $failed"
              else
                echo "  ‚è≥ $exp still running (HTTP $http_code)"
              fi
            fi
          done
          
          # Check if all experiments are finished
          all_done=true
          running_count=0
          for exp in "${experiments[@]}"; do
            if [[ "${status[$exp]}" == "running" ]]; then
              all_done=false
              running_count=$((running_count + 1))
            fi
          done
          
          echo "  üìä Status: $completed completed, $failed failed, $running_count running"
          
          if [[ "$all_done" == "true" ]]; then
            echo "üéâ All experiments finished!"
            break
          fi
          
          if [[ $i -lt $max_iterations ]]; then
            echo "  ‚è±Ô∏è Waiting ${polling_interval}s before next check..."
            sleep $polling_interval
          fi
        done
        
        echo "Final status: $completed completed, $failed failed"
        
        # Write outputs with explicit error handling
        echo "üîç Writing monitor step outputs..."
        
        echo "completed=$completed" >> $GITHUB_OUTPUT || {
          echo "‚ùå Failed to write completed output"
          exit 1
        }
        echo "failed=$failed" >> $GITHUB_OUTPUT || {
          echo "‚ùå Failed to write failed output"
          exit 1
        }
        
        # Debug: Print what we're outputting
        echo "  ‚úÖ completed=$completed"
        echo "  ‚úÖ failed=$failed"
        
        # Build results JSON safely - collect actual experiment results
        if [[ $completed -gt 0 ]]; then
          # Create a comprehensive results object with actual experiment data
          results_json="{"
          results_json+='"completed_experiments":'"$completed"','
          results_json+='"experiment_results":{'
          
          first=true
          for exp in "${experiments[@]}"; do
            if [[ "${status[$exp]}" == "completed" ]]; then
              if [[ "$first" == "false" ]]; then
                results_json+=','
              fi
              # Escape the experiment name and add its results
              exp_key=$(echo "$exp" | sed 's/"/\\"/g')
              exp_results="${results[$exp]}"
              # Safely escape the JSON value
              exp_results_escaped=$(echo "$exp_results" | sed 's/"/\\"/g' | tr -d '\n' | tr -d '\r')
              results_json+='"'"$exp_key"'":'"$exp_results"
              first=false
            fi
          done
          
          results_json+='}}'
        else
          results_json='{}'
        fi
        
        echo "results=$results_json" >> $GITHUB_OUTPUT || {
          echo "‚ùå Failed to write results output"
          exit 1
        }
        echo "  ‚úÖ results=$results_json"
        
        echo "üéâ Monitor step completed successfully!"

    - name: Validate thresholds
      shell: bash
      id: validate_thresholds
      if: always() && steps.monitor.outputs.completed > 0
      run: |
        echo "üéØ Validating performance thresholds..."
        
        # Check if thresholds are provided
        if [[ -z '${{ inputs.threshold }}' ]]; then
          echo "‚úì No thresholds provided, skipping validation"
          echo "threshold_passed=true" >> $GITHUB_OUTPUT
          echo "threshold_failures=[]" >> $GITHUB_OUTPUT
          exit 0
        fi
        
        threshold_config='${{ inputs.threshold }}'
        echo "üîç Threshold configuration: $threshold_config"
        
        # Get results from monitor step
        results='${{ steps.monitor.outputs.results }}'
        echo "üîç Results to validate: $results"
        
        # Initialize failure tracking
        failures=()
        threshold_passed=true
        
        # Parse threshold values
        eval_pass_rate_threshold=$(echo "$threshold_config" | jq -r '.eval_pass_rate // empty')
        cost_threshold=$(echo "$threshold_config" | jq -r '.cost // empty')
        latency_threshold=$(echo "$threshold_config" | jq -r '.latency // empty')
        tokens_threshold=$(echo "$threshold_config" | jq -r '.tokens // empty')
        semantic_similarity_threshold=$(echo "$threshold_config" | jq -r '.semantic_similarity // empty')
        
        echo "üéØ Parsed thresholds:"
        echo "  eval_pass_rate: $eval_pass_rate_threshold"
        echo "  cost: $cost_threshold"
        echo "  latency: $latency_threshold"
        echo "  tokens: $tokens_threshold"
        echo "  semantic_similarity: $semantic_similarity_threshold"
        
        # Parse and validate actual experiment results
        if [[ "$results" != "{}" && -n "$results" ]]; then
          echo "üìä Validating against actual results..."
          
          # Extract experiment results
          experiment_results=$(echo "$results" | jq -r '.experiment_results // {}')
          
          if [[ "$experiment_results" != "{}" ]]; then
            echo "üîç Found experiment results to validate"
            
            # Create temporary files to capture failures across subshell boundaries
            temp_failures_file=$(mktemp)
            temp_status_file=$(mktemp)
            echo "true" > "$temp_status_file"
            
            # Iterate through each experiment's results
            echo "$experiment_results" | jq -r 'keys[]' | while IFS= read -r exp_name; do
              exp_data=$(echo "$experiment_results" | jq -r --arg exp "$exp_name" '.[$exp]')
              
              echo "üß™ Validating thresholds for experiment: $exp_name"
              
              # Validate eval_pass_rate if threshold provided
              if [[ -n "$eval_pass_rate_threshold" ]]; then
                echo "  üîç Checking eval_pass_rate threshold: $eval_pass_rate_threshold"
                
                # Check total_validations_pass_percentage
                pass_percentage_data=$(echo "$exp_data" | jq -r '.total_validations_pass_percentage // {}')
                if [[ "$pass_percentage_data" != "{}" ]]; then
                  # Check each validation type
                  echo "$pass_percentage_data" | jq -r 'keys[]' | while IFS= read -r validation_type; do
                    pass_rate=$(echo "$pass_percentage_data" | jq -r --arg type "$validation_type" '.[$type]')
                    
                    if (( $(echo "$pass_rate < $eval_pass_rate_threshold" | bc -l) )); then
                      failure_msg="eval_pass_rate: $validation_type ($pass_rate) below threshold ($eval_pass_rate_threshold) in experiment $exp_name"
                      echo "$failure_msg" >> "$temp_failures_file"
                      echo "false" > "$temp_status_file"
                      echo "    ‚ùå $failure_msg"
                    else
                      echo "    ‚úÖ $validation_type: $pass_rate >= $eval_pass_rate_threshold"
                    fi
                  done
                else
                  echo "    ‚ö†Ô∏è No eval pass rate data found in experiment results"
                fi
              fi
              
              # Validate cost if threshold provided
              if [[ -n "$cost_threshold" ]]; then
                echo "  üîç Checking cost threshold: $cost_threshold"
                cost_value=$(echo "$exp_data" | jq -r '.cost // 0')
                
                if [[ "$cost_value" != "0" ]] && (( $(echo "$cost_value > $cost_threshold" | bc -l) )); then
                  failure_msg="cost: $cost_value above threshold ($cost_threshold) in experiment $exp_name"
                  echo "$failure_msg" >> "$temp_failures_file"
                  echo "false" > "$temp_status_file"
                  echo "    ‚ùå $failure_msg"
                else
                  echo "    ‚úÖ cost: $cost_value <= $cost_threshold (or cost is 0, skipped)"
                fi
              fi
              
              # Validate latency if threshold provided
              if [[ -n "$latency_threshold" ]]; then
                echo "  üîç Checking latency threshold: $latency_threshold"
                ttft_value=$(echo "$exp_data" | jq -r '.ttft // 0')
                
                if (( $(echo "$ttft_value > $latency_threshold" | bc -l) )); then
                  failure_msg="latency: $ttft_value ms above threshold ($latency_threshold ms) in experiment $exp_name"
                  echo "$failure_msg" >> "$temp_failures_file"
                  echo "false" > "$temp_status_file"
                  echo "    ‚ùå $failure_msg"
                else
                  echo "    ‚úÖ latency: $ttft_value ms <= $latency_threshold ms"
                fi
              fi
              
              # Validate tokens if threshold provided
              if [[ -n "$tokens_threshold" ]]; then
                echo "  üîç Checking tokens threshold: $tokens_threshold"
                tokens_value=$(echo "$exp_data" | jq -r '.tokens // 0')
                
                if (( $(echo "$tokens_value > $tokens_threshold" | bc -l) )); then
                  failure_msg="tokens: $tokens_value above threshold ($tokens_threshold) in experiment $exp_name"
                  echo "$failure_msg" >> "$temp_failures_file"
                  echo "false" > "$temp_status_file"
                  echo "    ‚ùå $failure_msg"
                else
                  echo "    ‚úÖ tokens: $tokens_value <= $tokens_threshold"
                fi
              fi
              
              # Validate semantic_similarity if threshold provided
              if [[ -n "$semantic_similarity_threshold" ]]; then
                echo "  üîç Checking semantic_similarity threshold: $semantic_similarity_threshold"
                similarity_value=$(echo "$exp_data" | jq -r '.semantic_similarity // -1')
                
                if [[ "$similarity_value" != "-1" ]] && (( $(echo "$similarity_value < $semantic_similarity_threshold" | bc -l) )); then
                  failure_msg="semantic_similarity: $similarity_value below threshold ($semantic_similarity_threshold) in experiment $exp_name"
                  echo "$failure_msg" >> "$temp_failures_file"
                  echo "false" > "$temp_status_file"
                  echo "    ‚ùå $failure_msg"
                elif [[ "$similarity_value" == "-1" ]]; then
                  echo "    ‚ö†Ô∏è semantic_similarity: no data available (-1), skipping validation"
                else
                  echo "    ‚úÖ semantic_similarity: $similarity_value >= $semantic_similarity_threshold"
                fi
              fi
            done
            
            # Read back the results from temporary files
            threshold_passed=$(cat "$temp_status_file")
            if [[ -f "$temp_failures_file" ]]; then
              while IFS= read -r line; do
                [[ -n "$line" ]] && failures+=("$line")
              done < "$temp_failures_file"
            fi
            
            # Clean up temporary files
            rm -f "$temp_failures_file" "$temp_status_file"
          else
            echo "‚ö†Ô∏è No experiment results found in results object"
          fi
        else
          echo "‚ö†Ô∏è No detailed results available for threshold validation"
          echo "‚ÑπÔ∏è Threshold validation will be skipped for this run"
        fi
        
        # Convert failures array to JSON
        if [[ ${#failures[@]} -eq 0 ]]; then
          failures_json="[]"
          echo "threshold_passed=true" >> $GITHUB_OUTPUT
        else
          failures_json=$(printf '%s\n' "${failures[@]}" | jq -R . | jq -s .)
          threshold_passed=false
          echo "threshold_passed=false" >> $GITHUB_OUTPUT
        fi
        
        echo "threshold_failures=$failures_json" >> $GITHUB_OUTPUT
        
        echo "üéØ Threshold validation completed"
        echo "  Passed: $threshold_passed"
        echo "  Failures: $failures_json"

    - name: Generate summary
      shell: bash
      id: summary
      if: always()
      run: |
        echo "üìä Generating build summary..."
        
        build_success="${{ steps.build.outputs.build_success || 'false' }}"
        completed="${{ steps.monitor.outputs.completed || '0' }}"
        failed="${{ steps.monitor.outputs.failed || '0' }}"
        threshold_passed="${{ steps.validate_thresholds.outputs.threshold_passed || 'true' }}"
        threshold_failures="${{ steps.validate_thresholds.outputs.threshold_failures || '[]' }}"
        
        # Debug: Print what values we received
        echo "üîç Summary step inputs:"
        echo "  build_success=$build_success"
        echo "  completed=$completed"
        echo "  failed=$failed"
        echo "  threshold_passed=$threshold_passed"
        echo "  threshold_failures=$threshold_failures"
        
        # Determine overall success
        if [[ "$build_success" == "true" && "$failed" == "0" && "$completed" -gt 0 && "$threshold_passed" == "true" ]]; then
          overall_success="true"
          status_emoji="‚úÖ"
          status_text="Success"
        else
          overall_success="false"
          status_emoji="‚ùå"
          if [[ "$threshold_passed" == "false" ]]; then
            status_text="Failed (Threshold violations)"
          elif [[ "$failed" -gt 0 ]]; then
            status_text="Failed (Experiment failures)"
          elif [[ "$build_success" != "true" ]]; then
            status_text="Failed (Build error)"
          else
            status_text="Failed"
          fi
        fi
        
        echo "success=$overall_success" >> $GITHUB_OUTPUT
        echo "completed_count=$completed" >> $GITHUB_OUTPUT
        echo "failed_count=$failed" >> $GITHUB_OUTPUT
        echo "threshold_failures=$threshold_failures" >> $GITHUB_OUTPUT
        
        # Create summary JSON with proper escaping
        summary=$(jq -nc \
          --arg status "$status_text" \
          --arg completed "$completed" \
          --arg failed "$failed" \
          --argjson success "$overall_success" \
          --argjson threshold_passed "$threshold_passed" \
          --argjson threshold_failures "$threshold_failures" \
          '{"status": $status, "success": $success, "completed_count": ($completed | tonumber), "failed_count": ($failed | tonumber), "total_count": (($completed | tonumber) + ($failed | tonumber)), "threshold_passed": $threshold_passed, "threshold_failures": $threshold_failures}')
        
        echo "results_summary=$summary" >> $GITHUB_OUTPUT
        
        # Generate GitHub Actions summary report
        echo "üìä Creating GitHub Actions summary report..."
        
        cat >> $GITHUB_STEP_SUMMARY << EOF
        # üöÄ Arato Build Summary
        
        ## Build Status: $status_emoji $status_text
        
        ### Experiment Results
        | Metric | Count |
        |--------|-------|
        | ‚úÖ Completed | $completed |
        | ‚ùå Failed | $failed |
        | üìä Total | $((completed + failed)) |
        
        $(if [[ -n '${{ inputs.threshold }}' ]]; then
          echo "### Performance Thresholds"
          echo "| Status | Result |"
          echo "|--------|--------|"
          echo "| üéØ Threshold Validation | $(if [[ "$threshold_passed" == "true" ]]; then echo "‚úÖ Passed"; else echo "‚ùå Failed"; fi) |"
          echo ""
          if [[ "$threshold_passed" == "false" && "$threshold_failures" != "[]" ]]; then
            echo "### ‚ö†Ô∏è Threshold Failures"
            echo "$threshold_failures" | jq -r '.[] | "- " + .'
            echo ""
          fi
        fi)
        
        ### Build Details
        - **Overall Success**: $overall_success
        - **API Base URL**: ${{ inputs.api_base_url }}
        - **Build Triggered**: $(date -u +"%Y-%m-%d %H:%M:%S UTC")
        $(if [[ -n '${{ inputs.threshold }}' ]]; then
          echo "- **Thresholds Configured**: Yes"
        else
          echo "- **Thresholds Configured**: No"
        fi)
        
        ### Experiment Configuration
        \`\`\`json
        ${{ inputs.experiments }}
        \`\`\`
        
        $(if [[ -n '${{ inputs.threshold }}' ]]; then
          echo "### Threshold Configuration"
          echo "\`\`\`json"
          echo '${{ inputs.threshold }}'
          echo "\`\`\`"
        fi)
        
        ---
        *Generated by [Arato AI](https://arato.ai) GitHub Action*
        EOF
        
        # Also log summary to console
        echo ""
        echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
        echo "üöÄ ARATO BUILD SUMMARY"
        echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
        echo "$status_emoji Status: $status_text"
        echo "‚úÖ Completed: $completed"
        echo "‚ùå Failed: $failed"
        echo "üìä Total: $((completed + failed))"
        echo "üéØ Thresholds Passed: $threshold_passed"
        if [[ "$threshold_passed" == "false" && "$threshold_failures" != "[]" ]]; then
          echo "‚ö†Ô∏è  Threshold Failures:"
          echo "$threshold_failures" | jq -r '.[] | "   - " + .'
        fi
        echo "üéØ Overall Success: $overall_success"
        echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
        

